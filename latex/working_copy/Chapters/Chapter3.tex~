\chapter{Experiment} 
\label{Chapter3} 
\lhead{Chapter 3. \emph{Experiment}} 

\section{Client side}

\subsection{Client server} 

SocketCluster-client makes the instanciation of a WebSocket clients on one core
quite straightforward. To deploy it on all available nodes, node.js
\texttt{fork()} function is used. A client code example is given in appendix
INSERERLA REF   ref{client}.

The first experiment is a safety test. It checks if \texttt{fork()} distributes
evenly the work among the cores.

\begin{center}
  \begin{tabular}{ | l | l |}
  \hline
  \multicolumn{2}{|c|}{Parameters} \\
  \hline
    Instance type &  amazon s3 m3.2xlarge\\ 
    Experiment time & 120 s \\
    Number of new communication created at each iteration & 15 \\
    Client creation period & 1 s \\
    Type of ping & random number \\ 
    Ping period & 2.5 s \\ 
  \hline
  \end{tabular}
\end{center}

\begin{figure}[H]
	\centering
		\includegraphics[width=0.49\textwidth]{./Figures/1_client.png}
		\includegraphics[width=0.49\textwidth]{./Figures/2_client.png}
	\caption[1+2_client]{client throughout}
	\label{fig:1+2_client}
\end{figure}


From figure \ref{fig:1+2_client} can be inferred that the client
implementation works flawlessly. Adding a second core enables twice as much
communication  to be established.

\subsection{Client browser}

Browsers can be configured to connect to one of the SocketCluster worker. For
example if the experiment is run locally, typing \texttt{localhost:8080} in the
url will make the browser listen to the port 8080. After what sending ping
thanks to \texttt{socket.emit('ping')} can help to check the throughout
performance. It also displays the growing number of pings a working has sent
since begenning of the experiment.

INSERT GRAPH

\section{Server side}

\subsection{Traditonnal engine.io implementation}

SocketCluster has been created to ease the creation of multi - core WebSocket
server. Logicaly the first experiment I carried out was to compare a WebSocket
to a traditionnal Engine.io server. 


The code I used for the client and server code I used to create the engine can
is given in appendix INSERER LA REF ::: ref{}

\begin{center}
  \begin{tabular}{ | l | l |}
  \hline
  \multicolumn{2}{|c|}{Parameters} \\
  \hline
    Instance type &  amazon s3 m3.2xlarge\\ 
    Experiment time & 120 s \\
    Number of new communication created at each iteration & 15 \\
    Client creation period & 1 s \\
    Type of ping & random number \\ 
    Ping period & 2.5 s \\ 
  \hline
  \end{tabular}
\end{center}
( copier coller code engine.io )

1 -

One balancer / worker 
engine.io

2 - 

two balancer / worker
engine.io

3 - context switching

server 1 core

B] section most influence frequence pings / size message / number communications

c] General rule

load balancer / store / worker





